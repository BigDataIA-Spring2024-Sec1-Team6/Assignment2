{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##This notebook explains the way to utilize SQLAlchemy to upload the structured data into a Snowflake database"
      ],
      "metadata": {
        "id": "9JP8Ax7gZLCJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Terminal Commands:**\n",
        "\n",
        "\n",
        "**Step 1:** Connect to your snowflake account\n",
        "\n",
        "- snowsql -a CKMFZWO-AFA59273 -u akshitapathania\n",
        "\n",
        "**Step 2:** Enter Password\n",
        "\n",
        "- {password}\n",
        "\n",
        "**Step 3:** Create a Database called 'TEXT_EXTRACTION'\n",
        "\n",
        "- CREATE OR REPLACE DATABASE TEXT_EXTRACTION;\n",
        "\n",
        "(To see your created database along with the schema:\n",
        "\n",
        "SELECT CURRENT_DATABASE(), CURRENT_SCHEMA();\n",
        "\n",
        ")\n",
        "\n",
        "**Step 4:** Create a Warehouse\n",
        "\n",
        "- CREATE OR REPLACE WAREHOUSE text_extraction_wh WITH\n",
        "                  WAREHOUSE_SIZE='X-SMALL'\n",
        "                  AUTO_SUSPEND = 180\n",
        "                  AUTO_RESUME = TRUE\n",
        "                  INITIALLY_SUSPENDED=TRUE;\n",
        "\n",
        "(To see your created warehouse:\n",
        "\n",
        "SELECT CURRENT_WAREHOUSE();\n",
        "\n",
        ")\n",
        "\n",
        "##**Perform step 5 and 6 once the code below is executed on Google Colab:**\n",
        "\n",
        "**Step 5:** Showcase all the tables present\n",
        "\n",
        "- SHOW TABLES;\n",
        "\n",
        "**Step 6:** Display values in the table\n",
        "\n",
        "- SELECT * FROM STRUCTURED_DATA;\n"
      ],
      "metadata": {
        "id": "H8JtvjcU5QiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensuring that we have access to a Snowflake account and download SQLAlchemy."
      ],
      "metadata": {
        "id": "WPOfuZj4zGIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install SQLAlchemy snowflake-sqlalchemy snowflake-connector-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbnwgyU0wdma",
        "outputId": "909e4806-d024-4cc3-cbe7-5bc026e839d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SQLAlchemy in /usr/local/lib/python3.10/dist-packages (1.4.51)\n",
            "Requirement already satisfied: snowflake-sqlalchemy in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: snowflake-connector-python in /usr/local/lib/python3.10/dist-packages (3.7.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy) (3.0.3)\n",
            "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (1.5.1)\n",
            "Requirement already satisfied: cffi<2.0.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (1.16.0)\n",
            "Requirement already satisfied: cryptography<42.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (41.0.7)\n",
            "Requirement already satisfied: pyOpenSSL<24.0.0,>=16.2.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (23.3.0)\n",
            "Requirement already satisfied: pyjwt<3.0.0 in /usr/lib/python3/dist-packages (from snowflake-connector-python) (2.3.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (2023.4)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (2.31.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (4.9.0)\n",
            "Requirement already satisfied: filelock<4,>=3.5 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (3.13.1)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (2.4.0)\n",
            "Requirement already satisfied: platformdirs<4.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (3.11.0)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (0.12.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.21)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->snowflake-connector-python) (2.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the required libraries"
      ],
      "metadata": {
        "id": "33o93uZZ01UX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "4JhLXIxo0wO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using SQLAlchemy to connect to our Snowflake account by providing connection details such as username, password, account name, database name, schema name, and warehouse name."
      ],
      "metadata": {
        "id": "CQvlM7CKzSmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "snowflake_username = 'akshitapathania'\n",
        "snowflake_password = '***********'\n",
        "snowflake_account = 'CKMFZWO-AFA59273'\n",
        "snowflake_database = 'text_extraction'\n",
        "snowflake_schema = 'public'\n",
        "snowflake_warehouse = 'text_extraction_wh'\n",
        "\n",
        "# SQLAlchemy Snowflake connection string\n",
        "connection_string = f'snowflake://{snowflake_username}:{snowflake_password}@{snowflake_account}/{snowflake_database}?warehouse={snowflake_warehouse}&schema={snowflake_schema}'\n"
      ],
      "metadata": {
        "id": "9dL4QrEk03-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the data that we want to upload into Snowflake. This will be structured data that we have extracted from the website and the PDFs."
      ],
      "metadata": {
        "id": "Gp7ZouEkzcz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create SQLAlchemy engine\n",
        "engine = create_engine(connection_string)\n"
      ],
      "metadata": {
        "id": "392HKfXHZncU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we define the table structure in Snowflake. This involves creating a table with appropriate columns to store data."
      ],
      "metadata": {
        "id": "QaRNZqniggCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define metadata\n",
        "metadata = MetaData()\n",
        "\n",
        "# Define the table structure\n",
        "table_name = 'structured_data'\n",
        "table = Table(\n",
        "    table_name,\n",
        "    metadata,\n",
        "    Column('id', Integer, primary_key=True),\n",
        "    Column('topic_name', String),\n",
        "    Column('year', String),\n",
        "    Column('level', String),\n",
        "    Column('introduction_summary', String),\n",
        "    Column('learning_outcomes', String),\n",
        "    Column('summary_page_link', String),\n",
        "    Column('pdf_file_link', String)\n",
        ")"
      ],
      "metadata": {
        "id": "eKzeR3GcZoJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have defined the table structure, we create the table in Snowflake using SQLAlchemy's create_all() method."
      ],
      "metadata": {
        "id": "vXKiTjcPgtiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create table in Snowflake if it doesn't exist\n",
        "if not engine.dialect.has_table(engine, table_name):\n",
        "    metadata.create_all(engine)"
      ],
      "metadata": {
        "id": "lMpS0AhaZrTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then insert the data into the Snowflake table created. We used SQLAlchemy's execute() method to execute an INSERT SQL statement."
      ],
      "metadata": {
        "id": "jntE5cFrg1sV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to insert data into Snowflake\n",
        "def insert_data(data):\n",
        "    with engine.connect() as conn:\n",
        "        conn.execute(table.insert().values(data))\n"
      ],
      "metadata": {
        "id": "MrKg5SJoZuUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After inserting the data, commit the changes to persist them in Snowflake."
      ],
      "metadata": {
        "id": "OAGhI_tKhCVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your CSV file\n",
        "csv_file_path = 'refresher_readings.csv'\n",
        "\n",
        "# Read data from CSV file\n",
        "data_from_csv = pd.read_csv(csv_file_path).fillna('')"
      ],
      "metadata": {
        "id": "LzPixNB-__ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrame to list of dictionaries with correct keys\n",
        "data_to_insert = data_from_csv.rename(columns={\n",
        "    'Title': 'topic_name',\n",
        "    'Year': 'year',\n",
        "    'Level': 'level',\n",
        "    'Introduction Summary': 'introduction_summary',\n",
        "    'Learning Outcomes': 'learning_outcomes',\n",
        "    'Link to Summary Page': 'summary_page_link',\n",
        "    'Link to PDF File': 'pdf_file_link'\n",
        "}).to_dict(orient='records')\n",
        "\n",
        "# Insert data into Snowflake\n",
        "for data in data_to_insert:\n",
        "    insert_data(data)\n",
        "\n",
        "print(\"Data upload completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc3ST5jfZzBU",
        "outputId": "ae36ee59-628a-4c3d-a64b-ea3d344fd2e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data upload completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now verify the above upload process by opening the web-based interface of Snowflake, by going into the databases and the table will be displayed there with the uploaded data.\n",
        "\n",
        "We can also run Step 5 and 6 commands on the terminal to verify."
      ],
      "metadata": {
        "id": "GMdB2b1hZyYt"
      }
    }
  ]
}